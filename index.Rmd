---
title: "Computational Musicology -- Zoe Wong"
date: "2022/3/2"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---
```{r, include=FALSE}
library(compmus)
library(ggplot2)
library(plotly)
library(tidyverse)
library(spotifyr)

canto <- get_playlist_audio_features("", "57WgAlUaNcdk6En5fD5IeZ")
mandarin <- get_playlist_audio_features("", "05GSdBKp8ZZwlVA4czOFrM")
korean <- get_playlist_audio_features("", "0tFjLsZ50AsfehSNdl6YOc")
english <- get_playlist_audio_features("", "1tFMVzk46FL7SKkNvDftFh")
taiwanese <- get_playlist_audio_features("","3Q0ZWuIxIybBYql1xRCDZi")
japan <- get_playlist_audio_features("", "14vCVdgEYVQ8p1ewq5twRq")
awards <-
  bind_rows(
    mandarin %>% mutate(category = "Mandarin"),
    korean %>% mutate(category = "Korean"),
    canto %>% mutate(category = "Cantonese"),
    japan %>% mutate(category = "Japan"),
    english %>% mutate(category = "English"),
    taiwanese %>% mutate(category = "Taiwanese")
)
blindinglight <-
  get_tidy_audio_analysis("0VjIjW4GlUZAMYd2vXMi3b?si=846801ced0774ffb") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
inyoureyes <-
  get_tidy_audio_analysis("7szuecWAPwGoV1e5vGu8tl?si=66f65d5a10ef4df4") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```
### Introduction

In this course, I propose a computational analysis of my personal playlist on Spotify. My pocket playlist comprises disco, dance-pop, and sentimental ballads, which I have been accumulating since November 2020. The collection of these songs is solely influenced by my YouTube explore and radio shows. The size of my corpus is around 90 songs in the playlist from various genres, such as Korean, English, Mandarin, Cantonese, Taiwanese, and Japanese. The diversity of my favourites is inspirational to my project and I hope to understand the mechanism behind my choice.

The analysis would be conducted according to the geographical region/verbal language of the playlist: United States (English), Korea (Korean), Hong Kong (Cantonese), Taiwan (Mandarin/Taiwanese) and Japan (Japanese). Each region has its distinctive features, such as: danceability, acousticness, valence and tempo; however, each connects each with the combination of its genre and languages, and this project aims to evaluate their similarities and patterns. Thus, in each category, both typical and unique tracks are selected, to represent or emphasize their typicality/atypicality.

Notes: The written words of Cantonese, Mandarin and Taiwanese are all based on Chinese, in different accents.

Typical tracks:
TWICE “I CAN’T STOP ME” It is an inclusive track with a common genre of retro and dance-pop, and Korean Pop. The catchy melodies and modern pop conclude the typical genre of my playlist.

KYLIE MINOGUE, DUA LIPA “REAL GROOVE” The elements of its funk bass and disco-pop frequently appear on my playlist as an English pop.

Kay Tse “囍帖街 (The Wedding Invitations Streets)” It represents another genre of the sentimental ballad, with a slow tempo and storytelling tones.

Atypical tracks:
Official HIGE DANdism “I Love…” It is one of the few Japanese songs in my playlist, and its genre belongs to its rock music.

Olivia Ong “Fly Me to the moon” It is the only ballad song in English on my playlist.

Mirror “Ignited” It is an exclusive electronic and dance-pop music in Cantonese.


***
Notes:

The written words of Cantonese, Mandarin and Taiwanese are all based on Chinese, in different accents.


  
  
### Language as Genre: Danceability

```{r, echo=FALSE, fig.align ='center'}
awards %>%
  ggplot(aes(x = category, y = danceability)) +
  geom_violin() + labs(title =
  "Table 1: Danceability distribution in different languages")
 
```

***
Table 1: Danceability distribution in different languages

English has the highest medium of danceability among all genres, followed by Korean. Both Cantonese and Taiwanese have the even distribution of danceability between 0.4 and 0.8. Mandarin and Japanese have the lower medium of danceability among all genres. Overall, all tracks are higher than 0.5, which symbolizes my tendency in listening music with high dancebility



### Language as Genre: Tempo

```{r, echo=FALSE}
 tempo_category <- awards %>%
  ggplot(aes(x = category, y = tempo)) +
  geom_boxplot() + labs(title =
  "Table 2: Tempo distribution in different languages") 

ggplotly(tempo_category)
```

***
Table 2: Tempo distribution in different languages

Vice versa, the distribution in tempo shows an opposite pattern comparing to danceability, where English has the lowest medium, exluding atypical tracks: Starboy, Blinding Lights (The Weeknd) and Stay (The Kid Laroi ft. Justin Bieber). Along with Cantonese, both distribution are the narrowest between 100 and 130 BPM. Japanese and Taiwanese have the highest medium of tempo at 150 BPM. Overall, most of the medium of tempo distribution locate around 125 BPM.





### Language as Genre: Acousticness

```{r, echo=FALSE}
 valence_category <- awards %>%
  ggplot(aes(x = valence, group = category, fill = category)) +
  geom_density(adjust=1.5, alpha=.3) + labs(title =
  "Table 3: Valence distribution in different languages") + facet_wrap(~category)

ggplotly(valence_category)
```

***
Table 3: Valence Distribution in different languages



### Comparison of Chroma features of The Weeknd

```{r, echo=FALSE, fig.align='center'}

bl <- blindinglight %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "[4] Chromagram of 'Blinding light' by The Weeknd") +
  theme_minimal() +
  scale_fill_viridis_c()

ggplotly(bl)

```

***
Table 4: Chromagram of "Blinding Light" (The Weeknd) 

From table 4, we can see that F chord has a consistent pattern of its timbre feature in "Blinding Light". We might hardly recognize the chorus on the chromagram; however tracing back to the track, a strong rhythmic echo in F chord clearly stands out as the bass of the song. We can also see a cycle throughout the entire song, where F chord goes to C, then C# and keep circulating.

### Chromagram features of "In Your Eyes"

```{r, echo=FALSE, fig.align='center'}
iyy <- inyoureyes %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "[5] Chromagram of 'In your eyes' by The Weeknd") +
  theme_minimal() +
  scale_fill_viridis_c()

ggplotly(iyy)
```

***
Table 5: Chromagram of "In Your Eyes" (The Weeknd) 

From table 5, the euclidean timbre features show the route of the bass, from G to C to F and back to G. It is relatively obvious compared to above, with many sudden change between chords, and it is not the chorus but the bass of the track. By comparing these 2 songs from the same artist, we can see that C and F chords often appear as the key timbre.

**Both tracks are part of the album "After Hours" by The Weeknd. However, I have no clue to put two ggplotly into one textbox (they would overlap or i cant scroll down). planning to put both table 3 and table 4 together for better comparison


### Self-Similarity Matrix of "I Can't Stop me" by Twice
```{r, include=FALSE}
icsm <-
  get_tidy_audio_analysis("37ZtpRBkHcaq6hHy0X98zn?si=9181c96d417c4ec3") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "manhattan"              # Change summary & norm.
      )
  )
```

```{r, echo=FALSE}
icsm %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = " [6] Timbre cepstogram of 'I can't stop me' ")

icsm %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = " [7] Pitches cepstogram of 'I can't stop me' ")

```

***

Correction neededddddddd!!!!!!!!


Table 6: Pitch of "Blinding Light" (The Weeknd)

table 7: Timbre of "Blinding Light" (The Weeknd)

From table 6, we can see that the pitch class of "Blinding Light" are consistent throughout the track. If we zoom into the section from 50 secs to around 90 secs, 110 secs to around 190 secs, the patterns are identicial, referring to the chorus of track.

From table 7, the sections (10-25 secs, 80-90 secs, 140-150 secs, 160-180 secs) in dark blue represents the chorus with solely instrumental music. Comparing to table 5, the dark blue area emphasizes the chorus without human voices. Between 100-135 sec, a small diagonal line symbolizes the repetition of section between 50-75 sec, that we could identify as the verse and pre-chorus.

"Blinding Light" thus could be divided as two divisions (verse+pre-chorus [A] and chorus [B]), and its pattern is 'BABABB'.



### Chordogram of 'Yoru ni kakeru' by YOASOBI

```{r, include=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```
```{r, include=FALSE}
yoru <-
  get_tidy_audio_analysis("3dPtXHP0oXQ4HCWHsOA9js?si=d016c5d1d5174bf1") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r, echo=FALSE}
yoru %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "[8] Chordogram of 'Yoru ni kakeru 夜に駆ける (Run to the night)' by YOASOBI")
```

***
Table 8:



### Dynamic Time Warping of 'Real Groove' by Kylie Minogue

```{r, include=FALSE}
realgroove <-
  get_tidy_audio_analysis("6E6F7dSFvpV6NRBjcSZpEP?si=47f759d76823439c") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
rg2054 <-
  get_tidy_audio_analysis("2J3Mmybwue0jyQ0UVMYurH") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```
```{r, echo=FALSE}
compmus_long_distance(
  realgroove %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  rg2054 %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "cosine"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "The Tallis Scholars", y = "La Chapelle Royale") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

```












